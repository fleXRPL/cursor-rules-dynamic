// FastAPI Scalable API Architecture Guide
// Author: {{AUTHOR_NAME}} ({{GITHUB_USERNAME}})

// What you can build with this ruleset:
A highly scalable FastAPI application designed for large-scale deployments:
- Microservices-ready architecture
- High-performance API endpoints
- Distributed system patterns
- Horizontal scaling capabilities
- Load balancing ready
- Service mesh integration
- Monitoring and observability
- Containerization support

// Project Structure
src/
  api/
    v1/
      routers/       # API route modules
      schemas/       # Request/Response models
      dependencies/  # Endpoint dependencies
  core/
    config/          # Environment and app config
    events/          # Event handlers and buses
    middleware/      # Custom middleware
    monitoring/      # Metrics and tracing
  infrastructure/
    database/        # Database modules
      migrations/    # Alembic migrations
      models/        # SQLAlchemy models
    cache/           # Caching layer
    queue/           # Message queues
    storage/         # File storage
  services/          # Business logic services
    auth/            # Authentication service
    notification/    # Notification service
    background/      # Background tasks
  tests/
    integration/     # Integration tests
    load/            # Load tests
    unit/            # Unit tests
  utils/             # Shared utilities
  main.py            # Application entry

// Development Guidelines
1. Scalability Patterns:
   - Use asynchronous programming everywhere
   - Implement proper connection pooling
   - Design for statelessness
   - Use distributed caching
   - Implement circuit breakers
   - Use message queues for async tasks

2. Performance Optimization:
   - Implement response compression
   - Use efficient serialization
   - Optimize database queries
   - Implement proper indexing
   - Use bulk operations
   - Cache frequently accessed data

3. Monitoring and Observability:
   - Implement structured logging
   - Use distributed tracing
   - Monitor key metrics
   - Set up health checks
   - Track performance metrics
   - Implement proper alerting

4. Database Scaling:
   - Use database sharding
   - Implement read replicas
   - Use connection pooling
   - Optimize query patterns
   - Implement proper indexes
   - Use database partitioning

// Dependencies
Core:
- fastapi>=0.100.0
- uvicorn[standard]>=0.23.0
- sqlalchemy[asyncio]>=2.0.0
- alembic>=1.11.0
- asyncpg>=0.28.0
- redis>=5.0.0
- prometheus-client>=0.17.0
- opentelemetry-api>=1.20.0

Optional:
- celery>=5.3.0
- kafka-python>=2.0.0
- elasticsearch>=8.0.0
- memcached>=1.59
- sentry-sdk>=1.30.0
- newrelic>=8.8.0

// Code Examples:

1. Circuit Breaker Pattern:
```python
from fastapi import FastAPI, HTTPException
from functools import wraps
import asyncio
import time

class CircuitBreaker:
    def __init__(self, failure_threshold=5, reset_timeout=60):
        self.failure_count = 0
        self.failure_threshold = failure_threshold
        self.reset_timeout = reset_timeout
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half-open

    async def __call__(self, func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            if self.state == "open":
                if time.time() - self.last_failure_time > self.reset_timeout:
                    self.state = "half-open"
                else:
                    raise HTTPException(status_code=503, detail="Service temporarily unavailable")

            try:
                result = await func(*args, **kwargs)
                if self.state == "half-open":
                    self.state = "closed"
                    self.failure_count = 0
                return result
            except Exception as e:
                self.failure_count += 1
                self.last_failure_time = time.time()
                if self.failure_count >= self.failure_threshold:
                    self.state = "open"
                raise e

        return wrapper

# Usage
@app.get("/api/users/{user_id}")
@circuit_breaker(failure_threshold=5, reset_timeout=60)
async def get_user(user_id: int):
    return await user_service.get_user(user_id)
```

2. Caching Layer Pattern:
```python
from fastapi import FastAPI, Depends
from redis import asyncio as aioredis
import json

class CacheLayer:
    def __init__(self, redis_url: str):
        self.redis = aioredis.from_url(redis_url)

    async def get_or_set(self, key: str, func, expire: int = 3600):
        # Try to get from cache
        cached = await self.redis.get(key)
        if cached:
            return json.loads(cached)

        # If not in cache, execute function and cache result
        result = await func()
        await self.redis.setex(
            key,
            expire,
            json.dumps(result, default=str)
        )
        return result

# Usage
cache = CacheLayer("redis://localhost")

@app.get("/api/products")
async def get_products(category: str):
    async def fetch_products():
        return await db.products.filter(category=category)

    return await cache.get_or_set(
        f"products:{category}",
        fetch_products,
        expire=3600
    )
```

3. Load Balancing Pattern:
```python
from fastapi import FastAPI, Request
from typing import List
import random

class LoadBalancer:
    def __init__(self, backends: List[str]):
        self.backends = backends
        self.current = 0

    def get_backend(self, strategy: str = "round_robin"):
        if strategy == "random":
            return random.choice(self.backends)
        elif strategy == "round_robin":
            backend = self.backends[self.current]
            self.current = (self.current + 1) % len(self.backends)
            return backend

app = FastAPI()
lb = LoadBalancer([
    "http://backend1:8000",
    "http://backend2:8000",
    "http://backend3:8000"
])

@app.middleware("http")
async def load_balancing_middleware(request: Request, call_next):
    backend = lb.get_backend()
    # Forward request to backend
    # Implementation details omitted for brevity
```

// Best Practices:
1. Design for horizontal scaling
2. Implement proper caching strategies
3. Use asynchronous operations
4. Implement circuit breakers
5. Use proper load balancing
6. Implement proper monitoring
7. Use message queues for async tasks
8. Implement proper error handling
9. Use proper database scaling
10. Implement proper security

// Security Considerations:
1. Implement rate limiting
2. Use proper authentication
3. Implement proper authorization
4. Use secure communications
5. Implement proper logging
6. Use proper input validation
7. Implement proper error handling
8. Use proper session management
9. Implement proper monitoring
10. Use proper security headers